#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de configuraci√≥n para el dataset de avocados
Verifica dependencias y prepara el entorno de trabajo
"""

import sys
import os
import subprocess
from pathlib import Path
import logging

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def check_python_version():
    """Verifica que se est√© usando Python 3.12"""
    logger.info("üêç Verificando versi√≥n de Python...")

    version = sys.version_info
    if version.major == 3 and version.minor == 12:
        logger.info(f"‚úÖ Python {version.major}.{version.minor}.{version.micro}")
        return True
    else:
        logger.error(f"‚ùå Python {version.major}.{version.minor}.{version.micro} detectado")
        logger.error("‚ö†Ô∏è Se requiere Python 3.12")
        return False


def check_required_files():
    """Verifica que los archivos principales del framework est√©n presentes"""
    logger.info("üìÅ Verificando archivos del framework...")

    required_files = [
        "main_sdm_modular.py",
        "process_avocado_dataset.py",
        "run_avocado_processing.py",
        "description/avocado_des.txt"
    ]

    missing_files = []
    for file_path in required_files:
        if not Path(file_path).exists():
            missing_files.append(file_path)

    if missing_files:
        logger.error("‚ùå Archivos faltantes:")
        for file_path in missing_files:
            logger.error(f"   {file_path}")
        return False

    logger.info("‚úÖ Todos los archivos del framework est√°n presentes")
    return True


def check_dataset_structure(dataset_path):
    """Verifica la estructura del dataset de avocados"""
    logger.info("ü•ë Verificando estructura del dataset...")

    dataset_path = Path(dataset_path)

    if not dataset_path.exists():
        logger.error(f"‚ùå Dataset no encontrado: {dataset_path}")
        logger.info("üí° Aseg√∫rate de que la ruta del dataset sea correcta")
        return False

    # Verificar archivos requeridos
    excel_file = dataset_path / "description.xlsx"
    images_folder = dataset_path / "images"

    if not excel_file.exists():
        logger.error(f"‚ùå Archivo Excel no encontrado: {excel_file}")
        return False

    if not images_folder.exists():
        logger.error(f"‚ùå Carpeta de im√°genes no encontrada: {images_folder}")
        return False

    try:
        import pandas as pd
        df = pd.read_excel(excel_file)

        required_columns = ["File Name", "Ripening Index Classification"]
        missing_columns = [col for col in required_columns if col not in df.columns]

        if missing_columns:
            logger.error(f"‚ùå Columnas faltantes en Excel: {missing_columns}")
            return False

        # Contar im√°genes
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
        image_files = [f for f in images_folder.iterdir()
                       if f.suffix.lower() in image_extensions]

        logger.info(f"‚úÖ Dataset v√°lido: {len(df)} registros, {len(image_files)} im√°genes")

        # Verificar clasificaciones
        classifications = df["Ripening Index Classification"].dropna().unique()
        logger.info(f"   Clasificaciones encontradas: {sorted(classifications)}")

    except Exception as e:
        logger.error(f"‚ùå Error leyendo Excel: {e}")
        return False

    return True


def check_dependencies():
    """Verifica que las dependencias est√©n instaladas"""
    logger.info("üì¶ Verificando dependencias...")

    # Mapeo correcto: nombre_pip -> nombre_importacion
    required_packages = {
        'torch': 'torch',
        'torchvision': 'torchvision',
        'opencv-python': 'cv2',  # CORREGIDO: opencv-python se importa como cv2
        'numpy': 'numpy',
        'pandas': 'pandas',
        'openpyxl': 'openpyxl',
        'matplotlib': 'matplotlib',
        'seaborn': 'seaborn',
        'Pillow': 'PIL'  # CORREGIDO: Pillow se importa como PIL
    }

    missing_packages = []
    for pip_name, import_name in required_packages.items():
        try:
            __import__(import_name)
            logger.info(f"   ‚úÖ {pip_name}")
        except ImportError:
            missing_packages.append(pip_name)
            logger.error(f"   ‚ùå {pip_name}")

    if missing_packages:
        logger.error("‚ùå Paquetes faltantes:")
        for package in missing_packages:
            logger.error(f"   {package}")
        logger.info("üí° Instalar con: pip install " + " ".join(missing_packages))
        return False

    logger.info("‚úÖ Todas las dependencias est√°n instaladas")
    return True


def check_sam2_checkpoint():
    """Verifica que el checkpoint de SAM2 est√© disponible"""
    logger.info("ü§ñ Verificando checkpoint SAM2...")

    checkpoint_path = Path("checkpoints/sam2_hiera_large.pt")

    if not checkpoint_path.exists():
        logger.error(f"‚ùå Checkpoint SAM2 no encontrado: {checkpoint_path}")
        logger.info("üí° Para descargar, ejecuta:")
        logger.info("   cd checkpoints && ./download_ckpts.sh")
        return False

    logger.info("‚úÖ Checkpoint SAM2 encontrado")
    return True


def create_example_commands(dataset_path, output_path):
    """Crea archivo con comandos de ejemplo"""
    logger.info("üìù Creando comandos de ejemplo...")

    commands_content = f'''#!/bin/bash
# Comandos de ejemplo para procesar dataset de avocados
# Dataset: {dataset_path}
# Salida: {output_path}

echo "ü•ë COMANDOS PARA PROCESAR DATASET DE AVOCADOS"
echo "=================================================="

echo "1Ô∏è‚É£ PREPARAR DATASET (crear splits train/val/test)"
python process_avocado_dataset.py \\
    --dataset_path "{dataset_path}" \\
    --output_path "{output_path}"

echo "2Ô∏è‚É£ PROCESAMIENTO COMPLETO CON ANALYTICS"
python main_sdm_modular.py \\
    --image_folder "{output_path}/prepared_dataset/Images/avocado" \\
    --output_folder "{output_path}/sdm_results" \\
    --description_file "{output_path}/prepared_dataset/description/avocado_des.txt" \\
    --avocado_ripening_dataset \\
    --enable_visualizations \\
    --box_visual \\
    --color_visual \\
    --save_json \\
    --verbose

echo "3Ô∏è‚É£ PIPELINE AUTOM√ÅTICO (todo en uno)"
python run_avocado_processing.py \\
    --dataset_path "{dataset_path}" \\
    --output_path "{output_path}"

echo "4Ô∏è‚É£ SOLO PREPARACI√ìN DEL DATASET"
python run_avocado_processing.py \\
    --dataset_path "{dataset_path}" \\
    --output_path "{output_path}" \\
    --only_preparation

echo "5Ô∏è‚É£ SOLO SEGMENTACI√ìN (sin clasificaci√≥n)"
python main_sdm_modular.py \\
    --image_folder "{output_path}/prepared_dataset/Images/avocado" \\
    --output_folder "{output_path}/segmentation_only" \\
    --only_segmentation \\
    --enable_nms \\
    --verbose

echo "‚úÖ Comandos listos para usar!"
'''

    commands_file = Path("avocado_commands.sh")
    with open(commands_file, 'w', encoding='utf-8') as f:
        f.write(commands_content)

    # Hacer ejecutable
    import stat
    commands_file.chmod(commands_file.stat().st_mode | stat.S_IEXEC)

    logger.info(f"‚úÖ Comandos de ejemplo guardados en: {commands_file}")


def run_quick_test(dataset_path):
    """Ejecuta una prueba r√°pida del sistema"""
    logger.info("üß™ Ejecutando prueba r√°pida...")

    try:
        # Test de importaci√≥n
        logger.info("   Probando importaciones...")

        # Test b√°sicos de importaci√≥n
        import torch
        import cv2
        import numpy as np
        import pandas as pd
        from PIL import Image

        logger.info("   ‚úÖ Importaciones b√°sicas exitosas")

        # Test de lectura del dataset si existe
        dataset_path = Path(dataset_path)
        if dataset_path.exists():
            logger.info("   Probando lectura del dataset...")
            excel_file = dataset_path / "description.xlsx"
            if excel_file.exists():
                df = pd.read_excel(excel_file)
                logger.info(f"   ‚úÖ Dataset le√≠do: {len(df)} registros")

        logger.info("üéâ Prueba r√°pida exitosa - Sistema listo!")
        return True

    except Exception as e:
        logger.error(f"‚ùå Error en prueba r√°pida: {e}")
        return False


def main():
    """Funci√≥n principal de configuraci√≥n"""
    print("ü•ë CONFIGURACI√ìN DEL DATASET DE AVOCADOS")
    print("=" * 50)

    # Solicitar rutas al usuario
    dataset_path = input("üìÅ Ruta al dataset (@avocado_dataset): ").strip()
    if not dataset_path:
        dataset_path = "./avocado_dataset"

    output_path = input("üìÅ Ruta de salida (./results_avocado): ").strip()
    if not output_path:
        output_path = "./results_avocado"

    print(f"\nüîç Verificando configuraci√≥n...")
    print(f"   Dataset: {dataset_path}")
    print(f"   Salida: {output_path}")

    # Lista de verificaciones
    checks = [
        ("Versi√≥n de Python", lambda: check_python_version()),
        ("Archivos del framework", lambda: check_required_files()),
        ("Estructura del dataset", lambda: check_dataset_structure(dataset_path)),
        ("Dependencias de Python", lambda: check_dependencies()),
        ("Checkpoint SAM2", lambda: check_sam2_checkpoint())
    ]

    all_passed = True

    print("\nüîß VERIFICACIONES DEL SISTEMA")
    print("-" * 30)

    for check_name, check_func in checks:
        print(f"\n{check_name}:")
        try:
            result = check_func()
            if not result:
                all_passed = False
        except Exception as e:
            logger.error(f"‚ùå Error en {check_name}: {e}")
            all_passed = False

    print("\n" + "=" * 50)

    if all_passed:
        print("üéâ ¬°CONFIGURACI√ìN EXITOSA!")
        print("‚úÖ Todos los componentes est√°n listos")

        # Crear comandos de ejemplo
        create_example_commands(dataset_path, output_path)

        # Ejecutar prueba r√°pida
        if run_quick_test(dataset_path):
            print("\nüöÄ PR√ìXIMOS PASOS:")
            print("1. Revisa avocado_commands.sh para comandos de ejemplo")
            print("2. Ejecuta el pipeline autom√°tico:")
            print(f"   python run_avocado_processing.py --dataset_path '{dataset_path}' --output_path '{output_path}'")
            print("3. O ejecuta paso a paso siguiendo avocado_commands.sh")

    else:
        print("‚ùå CONFIGURACI√ìN INCOMPLETA")
        print("‚ö†Ô∏è Soluciona los problemas indicados arriba antes de continuar")
        sys.exit(1)


if __name__ == "__main__":
    main()