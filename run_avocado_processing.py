#!/usr/bin/env python3
"""
Script de ejemplo para ejecutar el procesamiento del dataset de avocados
Compatible con Python 3.12
Archivo: run_avocado_processing.py

Este script ejecuta el pipeline completo:
1. Procesa el dataset original con clasificaciÃ³n
2. Ejecuta SDM-D con configuraciÃ³n optimizada para avocados
"""

import os
import sys
import subprocess
import argparse
from pathlib import Path
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def run_command(command: str, description: str) -> bool:
    """
    Ejecuta un comando del sistema y maneja errores

    Args:
        command (str): Comando a ejecutar
        description (str): DescripciÃ³n del comando

    Returns:
        bool: True si el comando fue exitoso
    """
    logger.info(f"ğŸ”„ {description}...")
    logger.info(f"   Comando: {command}")

    try:
        result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)
        logger.info(f"âœ… {description} completado exitosamente")
        return True

    except subprocess.CalledProcessError as e:
        logger.error(f"âŒ Error en {description}:")
        logger.error(f"   CÃ³digo de salida: {e.returncode}")
        logger.error(f"   STDOUT: {e.stdout}")
        logger.error(f"   STDERR: {e.stderr}")
        return False
    except Exception as e:
        logger.error(f"âŒ Error inesperado en {description}: {e}")
        return False


def validate_paths(dataset_path: str, output_path: str) -> bool:
    """
    Valida que las rutas requeridas existan

    Args:
        dataset_path (str): Ruta al dataset original
        output_path (str): Ruta de salida

    Returns:
        bool: True si todas las rutas son vÃ¡lidas
    """
    dataset_path = Path(dataset_path)

    # Validar dataset original
    if not dataset_path.exists():
        logger.error(f"âŒ Dataset no encontrado: {dataset_path}")
        return False

    required_files = [
        dataset_path / "description.xlsx",
        dataset_path / "images"
    ]

    for file_path in required_files:
        if not file_path.exists():
            logger.error(f"âŒ Archivo/directorio requerido no encontrado: {file_path}")
            return False

    # Validar que existan algunas imÃ¡genes
    images_dir = dataset_path / "images"
    image_files = list(images_dir.glob("*.jpg")) + list(images_dir.glob("*.jpeg")) + list(images_dir.glob("*.png"))

    if len(image_files) == 0:
        logger.error(f"âŒ No se encontraron imÃ¡genes en: {images_dir}")
        return False

    logger.info(f"âœ… Rutas validadas: {len(image_files)} imÃ¡genes encontradas")
    return True


def process_avocado_dataset_pipeline(dataset_path: str, output_path: str,
                                     skip_preparation: bool = False,
                                     only_preparation: bool = False) -> bool:
    """
    Ejecuta el pipeline completo de procesamiento

    Args:
        dataset_path (str): Ruta al dataset original
        output_path (str): Ruta de salida
        skip_preparation (bool): Saltar preparaciÃ³n del dataset
        only_preparation (bool): Solo preparar dataset, no ejecutar SDM-D

    Returns:
        bool: True si el procesamiento fue exitoso
    """
    logger.info("ğŸ¥‘ Iniciando pipeline de procesamiento de avocados")
    logger.info("=" * 60)

    # Validar rutas
    if not validate_paths(dataset_path, output_path):
        return False

    output_path = Path(output_path)
    prepared_dataset_path = output_path / "prepared_dataset"

    # PASO 1: Preparar dataset (si no se salta)
    if not skip_preparation:
        logger.info("ğŸ“‹ PASO 1: Preparando dataset...")

        command = f"""python process_avocado_dataset.py \\
            --dataset_path "{dataset_path}" \\
            --output_path "{prepared_dataset_path}" \\
            --train_ratio 0.7 \\
            --val_ratio 0.15 \\
            --test_ratio 0.15"""

        if not run_command(command, "PreparaciÃ³n del dataset"):
            return False

        # Verificar que se creÃ³ correctamente
        if not (prepared_dataset_path / "Images" / "avocado").exists():
            logger.error("âŒ Error: El dataset preparado no se creÃ³ correctamente")
            return False

        logger.info(f"âœ… Dataset preparado en: {prepared_dataset_path}")
    else:
        logger.info("â­ï¸ Saltando preparaciÃ³n del dataset (usando dataset existente)")

        # Verificar que el dataset preparado existe
        if not prepared_dataset_path.exists():
            logger.error(f"âŒ Dataset preparado no encontrado: {prepared_dataset_path}")
            logger.error("   Ejecuta primero sin --skip_preparation")
            return False

    # Si solo queremos preparaciÃ³n, terminar aquÃ­
    if only_preparation:
        logger.info("âœ… Solo preparaciÃ³n solicitada - completado")
        return True

    # PASO 2: Ejecutar SDM-D con configuraciÃ³n optimizada
    logger.info("ğŸ”¬ PASO 2: Ejecutando SDM-D para avocados...")

    sdm_output_path = output_path / "sdm_output"

    command = f"""python main_sdm_modular.py \\
        --image_folder "{prepared_dataset_path}/Images/avocado" \\
        --output_folder "{sdm_output_path}" \\
        --description_file "{prepared_dataset_path}/description/avocado_des.txt" \\
        --enable_visualizations \\
        --box_visual \\
        --color_visual \\
        --avocado_analytics \\
        --enable_progress_monitor \\
        --save_json \\
        --verbose \\
        --points_per_side 32 \\
        --min_mask_area 100 \\
        --enable_nms \\
        --nms_threshold 0.8"""

    if not run_command(command, "Procesamiento SDM-D"):
        return False

    # PASO 3: Generar reporte final
    logger.info("ğŸ“Š PASO 3: Generando reporte final...")
    generate_final_summary(prepared_dataset_path, sdm_output_path, output_path)

    logger.info("ğŸ‰ Pipeline completado exitosamente!")
    logger.info(f"ğŸ“ Resultados finales en: {output_path}")

    return True


def generate_final_summary(prepared_path: Path, sdm_output_path: Path, output_path: Path):
    """
    Genera un resumen final del procesamiento

    Args:
        prepared_path (Path): Ruta del dataset preparado
        sdm_output_path (Path): Ruta de salida de SDM-D
        output_path (Path): Ruta de salida principal
    """
    try:
        summary_file = output_path / "processing_summary.txt"

        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("ğŸ¥‘ RESUMEN DEL PROCESAMIENTO DE AVOCADOS\n")
            f.write("=" * 50 + "\n\n")

            f.write("ğŸ“ ESTRUCTURA DE ARCHIVOS:\n")
            f.write(f"â”œâ”€â”€ Dataset preparado: {prepared_path}\n")
            f.write(f"â”‚   â”œâ”€â”€ Images/avocado/train/\n")
            f.write(f"â”‚   â”œâ”€â”€ Images/avocado/val/\n")
            f.write(f"â”‚   â”œâ”€â”€ Images/avocado/test/\n")
            f.write(f"â”‚   â””â”€â”€ description/avocado_des.txt\n")
            f.write(f"â”œâ”€â”€ Resultados SDM-D: {sdm_output_path}\n")
            f.write(f"â”‚   â”œâ”€â”€ mask/ (mÃ¡scaras de segmentaciÃ³n)\n")
            f.write(f"â”‚   â”œâ”€â”€ labels/ (etiquetas YOLO)\n")
            f.write(f"â”‚   â”œâ”€â”€ mask_color_visual/ (visualizaciones)\n")
            f.write(f"â”‚   â”œâ”€â”€ analytics/ (anÃ¡lisis de avocados)\n")
            f.write(f"â”‚   â””â”€â”€ logs/ (logs detallados)\n")
            f.write(f"â””â”€â”€ Resumen: {summary_file}\n\n")

            f.write("ğŸ¯ CLASIFICACIÃ“N DE MADURACIÃ“N:\n")
            f.write("1 - Underripe: Verde claro, firme\n")
            f.write("2 - Breaking: Iniciando maduraciÃ³n\n")
            f.write("3 - Ripe (First Stage): Verde oscuro, listo para cosecha\n")
            f.write("4 - Ripe (Second Stage): Verde oscuro/negro, Ã³ptimo\n")
            f.write("5 - Overripe: Muy oscuro, pasado del punto Ã³ptimo\n\n")

            f.write("ğŸ“Š ARCHIVOS GENERADOS:\n")
            f.write("- MÃ¡scaras de segmentaciÃ³n por imagen\n")
            f.write("- Etiquetas YOLO para entrenamiento\n")
            f.write("- Visualizaciones con cajas delimitadoras\n")
            f.write("- AnÃ¡lisis especÃ­fico de avocados\n")
            f.write("- Reportes JSON con mÃ©tricas\n")
            f.write("- Logs detallados del procesamiento\n\n")

            f.write("ğŸ”§ COMANDOS ÃšTILES:\n")
            f.write("# Ver logs del procesamiento:\n")
            f.write(f"tail -f {sdm_output_path}/logs/main_*.log\n\n")
            f.write("# Ver anÃ¡lisis de avocados:\n")
            f.write(f"ls {sdm_output_path}/analytics/\n\n")
            f.write("# Reejecutar solo SDM-D:\n")
            f.write(
                f"python run_avocado_processing.py --dataset_path [DATASET] --output_path {output_path} --skip_preparation\n\n")

            f.write("âœ… PROCESAMIENTO COMPLETADO EXITOSAMENTE\n")

        logger.info(f"ğŸ“‹ Resumen guardado en: {summary_file}")

    except Exception as e:
        logger.warning(f"âš ï¸ No se pudo generar el resumen: {e}")


def main():
    """FunciÃ³n principal"""
    parser = argparse.ArgumentParser(
        description='Pipeline completo para procesamiento de dataset de avocados',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
Ejemplos de uso:

    # Pipeline completo (preparaciÃ³n + SDM-D)
    python run_avocado_processing.py \\
        --dataset_path ./avocado_dataset \\
        --output_path ./results_avocado

    # Solo preparar dataset
    python run_avocado_processing.py \\
        --dataset_path ./avocado_dataset \\
        --output_path ./results_avocado \\
        --only_preparation

    # Solo ejecutar SDM-D (dataset ya preparado)
    python run_avocado_processing.py \\
        --dataset_path ./avocado_dataset \\
        --output_path ./results_avocado \\
        --skip_preparation

Estructura esperada del dataset:
    avocado_dataset/
    â”œâ”€â”€ description.xlsx    (con columnas: File Name, Ripening Index Classification)
    â””â”€â”€ images/            (archivos .jpg referenciados en el Excel)

        '''
    )

    parser.add_argument('--dataset_path', type=str, required=True,
                        help='Ruta al directorio del dataset original (@avocado_dataset)')
    parser.add_argument('--output_path', type=str, required=True,
                        help='Ruta donde guardar todos los resultados')
    parser.add_argument('--skip_preparation', action='store_true',
                        help='Saltar preparaciÃ³n del dataset (usar dataset ya preparado)')
    parser.add_argument('--only_preparation', action='store_true',
                        help='Solo preparar dataset, no ejecutar SDM-D')

    args = parser.parse_args()

    # Validar argumentos
    if args.skip_preparation and args.only_preparation:
        logger.error("âŒ No se pueden usar --skip_preparation y --only_preparation juntos")
        sys.exit(1)

    try:
        success = process_avocado_dataset_pipeline(
            args.dataset_path,
            args.output_path,
            args.skip_preparation,
            args.only_preparation
        )

        if success:
            logger.info("ğŸ‰ Pipeline ejecutado exitosamente!")
            sys.exit(0)
        else:
            logger.error("âŒ Pipeline fallÃ³")
            sys.exit(1)

    except KeyboardInterrupt:
        logger.info("âš ï¸ Procesamiento interrumpido por el usuario")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ Error inesperado: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()