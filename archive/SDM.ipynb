{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDM-D: Segmentation-Description-Matching-Distilling\n",
    "\n",
    "This notebook implements the SDM-D framework for fruit detection and segmentation without manual annotation.\n",
    "\n",
    "**Framework Overview:**\n",
    "- **SDM**: Segmentation-Description-Matching using SAM2 and OpenCLIP\n",
    "- **SDM-D**: Complete framework including knowledge distillation to smaller models\n",
    "\n",
    "## Requirements\n",
    "Make sure you have installed all dependencies from `requirements.txt` and have SAM2 and OpenCLIP properly set up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "import open_clip\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'sam2'))\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "\n",
    "from archive.utils import load_descriptions, create_output_folders\n",
    "from archive.utils import generate_all_sam_mask, label_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Parameters\n",
    "\n",
    "Set your parameters here instead of using command line arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Configuration:\n",
      "Image folder: ./Images/strawberry\n",
      "Output folder: ./output/strawberry\n",
      "Description file: ./description/straw_des.txt\n",
      "SAM2 checkpoint: ./checkpoints/sam2_hiera_large.pt\n",
      "Enable mask NMS: True\n",
      "Mask color visual: False\n",
      "Box visual: False\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters - Modify these according to your needs\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Required parameters\n",
    "        self.image_folder = './Images/strawberry'  # Path to the image segmentation folder\n",
    "        self.out_folder = './output/strawberry'    # Path to save mask outputs\n",
    "        self.des_file = '../description/straw_des.txt'  # Path to your prompt texts\n",
    "        \n",
    "        # Optional parameters\n",
    "        self.sam2_checkpoint = \"./checkpoints/sam2_hiera_large.pt\"  # SAM2 model checkpoint path\n",
    "        self.model_cfg = \"sam2_hiera_l.yaml\"  # SAM2 model config file\n",
    "        self.enable_mask_nms = True  # Whether to apply NMS to masks\n",
    "        self.mask_nms_thresh = 0.9  # Threshold for NMS mask overlap\n",
    "        self.save_anns = True  # Whether to save mask annotations\n",
    "        self.save_json = False  # Whether to save json\n",
    "        self.box_visual = False  # Whether to visual results\n",
    "        self.mask_color_visual = False  # Whether to visual mask results with color\n",
    "\n",
    "# Create configuration instance\n",
    "opt = Config()\n",
    "\n",
    "# Display current configuration\n",
    "print(\"Current Configuration:\")\n",
    "print(f\"Image folder: {opt.image_folder}\")\n",
    "print(f\"Output folder: {opt.out_folder}\")\n",
    "print(f\"Description file: {opt.des_file}\")\n",
    "print(f\"SAM2 checkpoint: {opt.sam2_checkpoint}\")\n",
    "print(f\"Enable mask NMS: {opt.enable_mask_nms}\")\n",
    "print(f\"Mask color visual: {opt.mask_color_visual}\")\n",
    "print(f\"Box visual: {opt.box_visual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup Folder Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder: ./output/strawberry/mask\n",
      "Created folder: ./output/strawberry/json\n",
      "Created folder: ./output/strawberry/labels\n",
      "Created folder: ./output/strawberry/mask_idx_visual\n",
      "Created folder: ./output/strawberry/label_box_visual\n",
      "Created folder: ./output/strawberry/mask_color_visual\n",
      "✅ Output folders created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Generate folder directories\n",
    "image_folder = opt.image_folder\n",
    "out_folder = opt.out_folder\n",
    "enable_mask_nms = opt.enable_mask_nms\n",
    "save_anns = opt.save_anns\n",
    "save_json = opt.save_json\n",
    "mask_color = opt.mask_color_visual\n",
    "lable_box_visual = opt.box_visual\n",
    "mask_nms_thresh = opt.mask_nms_thresh\n",
    "\n",
    "# Create output directories\n",
    "masks_segs_folder = os.path.join(out_folder, 'mask')\n",
    "json_save_dir = os.path.join(out_folder, 'json')\n",
    "label_output_dir = os.path.join(out_folder, 'labels')\n",
    "mask_ids_visual_folder = os.path.join(out_folder, 'mask_idx_visual')\n",
    "label_box_visual_dir = os.path.join(out_folder, 'label_box_visual')\n",
    "mask_color_visual_dir = os.path.join(out_folder, 'mask_color_visual')\n",
    "\n",
    "# Create all necessary folders\n",
    "create_output_folders(out_folder)\n",
    "\n",
    "print(\"✅ Output folders created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Descriptions and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded descriptions:\n",
      "0: 'a red strawberry with numerous points' -> ripe\n",
      "1: 'a pale green strawberry with numerous points' -> unripe\n",
      "2: 'a green veined strawberry leaf' -> leaf\n",
      "3: 'a long and thin stem' -> stem\n",
      "4: 'a white flower' -> flower\n",
      "5: 'soil or background or something else' -> others\n",
      "\n",
      "Label dictionary: {'ripe': 0, 'unripe': 1, 'leaf': 2, 'stem': 3, 'flower': 4, 'others': 5}\n"
     ]
    }
   ],
   "source": [
    "# Load descriptions from file\n",
    "texts, labels, label_dict = load_descriptions(opt.des_file)\n",
    "\n",
    "print(\"Loaded descriptions:\")\n",
    "for i, (text, label) in enumerate(zip(texts, labels)):\n",
    "    print(f\"{i}: '{text}' -> {label}\")\n",
    "    \n",
    "print(f\"\\nLabel dictionary: {label_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize OpenCLIP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenCLIP model initialized successfully!\n",
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenCLIP model\n",
    "torch.cuda.set_device(0)\n",
    "clip_model, _, clip_preprocessor = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "\n",
    "clip_model = clip_model.to('cuda')\n",
    "\n",
    "# Enable autocast for better performance\n",
    "torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "print(\"✅ OpenCLIP model initialized successfully!\")\n",
    "print(f\"Model device: {next(clip_model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initialize SAM2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SAM2 model initialized successfully!\n",
      "Your enable_mask_nms is True!\n"
     ]
    }
   ],
   "source": [
    "# Initialize SAM2 model\n",
    "sam2 = build_sam2(opt.model_cfg, opt.sam2_checkpoint, device='cuda', apply_postprocessing=False)\n",
    "mask_generator = SAM2AutomaticMaskGenerator(sam2, points_per_side=32, min_mask_region_area=50)\n",
    "\n",
    "print(f\"✅ SAM2 model initialized successfully!\")\n",
    "print(f\"Your enable_mask_nms is {opt.enable_mask_nms}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate All SAM Masks\n",
    "\n",
    "This step processes all images and generates segmentation masks using SAM2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting mask generation...\n",
      "Error with file label: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n",
      "Error with file img: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n",
      "Error with file label: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n",
      "Error with file img: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n",
      "Error with file label: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n",
      "Error with file img: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n",
      "✅ Mask generation completed!\n"
     ]
    }
   ],
   "source": [
    "# Generate all masks\n",
    "print(\"🚀 Starting mask generation...\")\n",
    "generate_all_sam_mask(\n",
    "    mask_generator, \n",
    "    image_folder, \n",
    "    masks_segs_folder, \n",
    "    json_save_dir, \n",
    "    mask_ids_visual_folder, \n",
    "    enable_mask_nms, \n",
    "    mask_nms_thresh, \n",
    "    save_anns, \n",
    "    save_json\n",
    ")\n",
    "print(\"✅ Mask generation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Label Assignment\n",
    "\n",
    "This step assigns labels to the generated masks using OpenCLIP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏷️ Starting label assignment...\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: './Images/strawberry/train/label'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIsADirectoryError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Label assignment\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m🏷️ Starting label assignment...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[43mlabel_assignment\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mclip_preprocessor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mimage_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmasks_segs_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlabel_output_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlabel_box_visual_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmask_color_visual_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m    \u001B[49m\u001B[43mclip_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlabel_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlable_box_visual\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmask_color\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m✅ Label assignment completed!\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/autoetiquetado/utils.py:436\u001B[39m, in \u001B[36mlabel_assignment\u001B[39m\u001B[34m(clip_preprocessor, image_folder, masks_segs_folder, label_output_dir, label_box_visual_dir, mask_color_visual_dir, model, texts, labels, label_dict, lable_box_visual, mask_color)\u001B[39m\n\u001B[32m    433\u001B[39m label_out_path = os.path.join(label_output_dir, img_train_folder, \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimg_idx\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.txt\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    434\u001B[39m os.makedirs(os.path.dirname(label_out_path), exist_ok=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m--> \u001B[39m\u001B[32m436\u001B[39m masks, results, rgb_image = \u001B[43mimage_label_get\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask_seg_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclip_preprocessor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask_color\u001B[49m\u001B[43m,\u001B[49m\u001B[43mlabel_out_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    438\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m lable_box_visual:\n\u001B[32m    439\u001B[39m     lable_box_visual_path = os.path.join(label_box_visual_dir, img_train_folder)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/autoetiquetado/utils.py:364\u001B[39m, in \u001B[36mimage_label_get\u001B[39m\u001B[34m(img_path, mask_out_folder, clip_preprocessor, model, texts, labels, label_dict, mask_color, label_out_path)\u001B[39m\n\u001B[32m    363\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mimage_label_get\u001B[39m(img_path, mask_out_folder, clip_preprocessor, model, texts, labels, label_dict, mask_color, label_out_path):\n\u001B[32m--> \u001B[39m\u001B[32m364\u001B[39m     image = \u001B[43mImage\u001B[49m\u001B[43m.\u001B[49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_path\u001B[49m\u001B[43m)\u001B[49m.convert(\u001B[33m'\u001B[39m\u001B[33mRGB\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    365\u001B[39m     rgb_image = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n\u001B[32m    366\u001B[39m     img_width, img_height = image.size\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/autoetiquetado/.venv/lib/python3.12/site-packages/PIL/Image.py:3505\u001B[39m, in \u001B[36mopen\u001B[39m\u001B[34m(fp, mode, formats)\u001B[39m\n\u001B[32m   3502\u001B[39m     filename = os.fspath(fp)\n\u001B[32m   3504\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[32m-> \u001B[39m\u001B[32m3505\u001B[39m     fp = \u001B[43mbuiltins\u001B[49m\u001B[43m.\u001B[49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   3506\u001B[39m     exclusive_fp = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m   3507\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[31mIsADirectoryError\u001B[39m: [Errno 21] Is a directory: './Images/strawberry/train/label'"
     ]
    }
   ],
   "source": [
    "# Label assignment\n",
    "print(\"🏷️ Starting label assignment...\")\n",
    "label_assignment(\n",
    "    clip_preprocessor, \n",
    "    image_folder, \n",
    "    masks_segs_folder, \n",
    "    label_output_dir, \n",
    "    label_box_visual_dir, \n",
    "    mask_color_visual_dir, \n",
    "    clip_model, \n",
    "    texts, \n",
    "    labels, \n",
    "    label_dict, \n",
    "    lable_box_visual, \n",
    "    mask_color\n",
    ")\n",
    "print(\"✅ Label assignment completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Results Summary\n",
    "\n",
    "Display information about the generated outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of results\n",
    "print(\"\\n📊 Processing Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Count generated files\n",
    "if os.path.exists(masks_segs_folder):\n",
    "    mask_count = sum([len(files) for r, d, files in os.walk(masks_segs_folder)])\n",
    "    print(f\"🎭 Generated masks: {mask_count}\")\n",
    "\n",
    "if os.path.exists(label_output_dir):\n",
    "    label_count = sum([len([f for f in files if f.endswith('.txt')]) for r, d, files in os.walk(label_output_dir)])\n",
    "    print(f\"🏷️ Generated label files: {label_count}\")\n",
    "\n",
    "print(f\"\\n📁 Output structure:\")\n",
    "print(f\"├── mask/               # Instance segmentation masks\")\n",
    "print(f\"├── labels/             # YOLO format labels\")\n",
    "if save_anns:\n",
    "    print(f\"├── mask_idx_visual/    # Mask visualization with indices\")\n",
    "if save_json:\n",
    "    print(f\"├── json/               # Mask metadata in JSON format\")\n",
    "if lable_box_visual:\n",
    "    print(f\"├── label_box_visual/   # Bounding box visualizations\")\n",
    "if mask_color:\n",
    "    print(f\"├── mask_color_visual/  # Colored mask visualizations\")\n",
    "\n",
    "print(f\"\\n✨ All outputs saved to: {out_folder}\")\n",
    "print(\"\\n🎉 SDM processing completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Optional: Visualization and Analysis\n",
    "\n",
    "Add some basic visualization of results if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Quick visualization of some results\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def show_sample_results(image_folder, output_folder, num_samples=2):\n",
    "    \"\"\"Display sample results for quick inspection\"\"\"\n",
    "    \n",
    "    # Get list of processed images\n",
    "    processed_images = []\n",
    "    for root, dirs, files in os.walk(image_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                processed_images.append(os.path.join(root, file))\n",
    "    \n",
    "    # Show sample results\n",
    "    num_samples = min(num_samples, len(processed_images))\n",
    "    \n",
    "    if num_samples > 0:\n",
    "        fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
    "        if num_samples == 1:\n",
    "            axes = [axes]\n",
    "            \n",
    "        for i in range(num_samples):\n",
    "            img_path = processed_images[i]\n",
    "            img = cv2.imread(img_path)\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            axes[i].imshow(img_rgb)\n",
    "            axes[i].set_title(f\"Sample {i+1}: {os.path.basename(img_path)}\")\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Displayed {num_samples} sample images from processing.\")\n",
    "    else:\n",
    "        print(\"No processed images found to display.\")\n",
    "\n",
    "# Uncomment the line below to show sample results\n",
    "# show_sample_results(image_folder, out_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Next Steps\n",
    "\n",
    "After running SDM, you can:\n",
    "\n",
    "1. **Convert labels for different tasks:**\n",
    "   - For object detection: Use `seg2label/seg2det.py`\n",
    "   - For semantic segmentation: Use `seg2label/seg2seman.py`\n",
    "   - For specific labels: Use `seg2label/extract_label_needed.py`\n",
    "\n",
    "2. **Knowledge Distillation (SDM-D):**\n",
    "   - Train smaller models using the generated pseudo-labels\n",
    "   - Use any architecture (YOLOv8, EfficientDet, etc.) as student models\n",
    "\n",
    "3. **Fine-tuning:**\n",
    "   - Use few-shot learning with manual labels for better performance\n",
    "   - Experiment with different prompt designs in the description file\n",
    "\n",
    "For more details, refer to the original paper and documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
